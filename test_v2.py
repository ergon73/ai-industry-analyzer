# test_v2.py - –¢–µ—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è v2 —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π

import os
import json
from crewai import Agent, Task, Crew, Process
from crewai_tools import BaseTool
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# –ó–∞–≥—Ä—É–∂–∞–µ–º API –∫–ª—é—á–∏
load_dotenv()

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏
smart_llm = ChatOpenAI(model_name="gpt-4.1", temperature=0.1)
fast_llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.1)

print(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {smart_llm.model_name}")
print(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á: {fast_llm.model_name}")

# –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
test_articles = [
    {
        "source": "The Verge",
        "title": "OpenAI launches new GPT-4 model with improved capabilities",
        "link": "https://example.com/1",
        "text": "OpenAI has released a new version of GPT-4 with enhanced performance..."
    },
    {
        "source": "TechCrunch", 
        "title": "OpenAI introduces GPT-4 update with better reasoning",
        "link": "https://example.com/2",
        "text": "OpenAI announced an updated GPT-4 model that shows improved reasoning..."
    },
    {
        "source": "Ars Technica",
        "title": "Microsoft invests $10 billion in OpenAI partnership",
        "link": "https://example.com/3", 
        "text": "Microsoft has announced a $10 billion investment in OpenAI..."
    },
    {
        "source": "VentureBeat",
        "title": "AI coding tools market grows rapidly",
        "link": "https://example.com/4",
        "text": "The market for AI-powered coding tools is experiencing rapid growth..."
    }
]

# –ê–≥–µ–Ω—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
deduplication_agent = Agent(
    role="–ê–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π",
    goal="–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—é–∂–µ—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤–∏—Ç—å –¢–û–ü-10.",
    backstory="–í—ã ‚Äî –≥–ª–∞–≤–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ —Å –æ—Å—Ç—Ä—ã–º –Ω—é—Ö–æ–º –Ω–∞ –≤–∞–∂–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏.",
    llm=smart_llm,
    verbose=True
)

trend_analyst = Agent(
    role='–ê–Ω–∞–ª–∏—Ç–∏–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤',
    goal="–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¢–û–ü-10 –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –≤—ã–¥–µ–ª–∏—Ç—å 5 –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤.",
    backstory="–í—ã ‚Äî data-–∞–Ω–∞–ª–∏—Ç–∏–∫ —Å –≥–ª—É–±–æ–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º —Ä—ã–Ω–∫–∞ –ò–ò.",
    llm=smart_llm,
    verbose=True
)

strategic_reviewer = Agent(
    role='–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å',
    goal="–°–æ–∑–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç —Å –¢–û–ü-10 –∏ –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–µ–Ω–¥–æ–≤.",
    backstory="–í—ã ‚Äî '–ø—Ä–∞–≤–∞—è —Ä—É–∫–∞' —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞.",
    llm=fast_llm,
    verbose=True
)

# –ó–∞–¥–∞—á–∏
task_deduplicate = Task(
    description="""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –∏:
    1. –ù–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Å–º—ã—Å–ª—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
    2. –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—é–∂–µ—Ç—ã
    3. –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—é–∂–µ—Ç–∞
    4. –°–æ—Å—Ç–∞–≤–∏—Ç—å –¢–û–ü-10 –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏""",
    expected_output="–û—Ç—á–µ—Ç —Å –¢–û–ü-10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.",
    agent=deduplication_agent
)

task_analyze = Task(
    description="–ù–∞ –æ—Å–Ω–æ–≤–µ –¢–û–ü-10 –Ω–æ–≤–æ—Å—Ç–µ–π –≤—ã–¥–µ–ª–∏ 5 –≥–ª–∞–≤–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤.",
    expected_output="–°–ø–∏—Å–æ–∫ 5 —Ç—Ä–µ–Ω–¥–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.",
    agent=trend_analyst,
    context=[task_deduplicate]
)

task_report = Task(
    description="–°–æ–∑–¥–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç —Å –¢–û–ü-10 –∏ –∞–Ω–∞–ª–∏–∑–æ–º —Ç—Ä–µ–Ω–¥–æ–≤.",
    expected_output="–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.",
    agent=strategic_reviewer,
    context=[task_deduplicate, task_analyze]
)

# Crew
test_crew = Crew(
    agents=[deduplication_agent, trend_analyst, strategic_reviewer],
    tasks=[task_deduplicate, task_analyze, task_report],
    process=Process.sequential,
    verbose=True
)

if __name__ == "__main__":
    try:
        print("üöÄ –¢–µ—Å—Ç–∏—Ä—É—é v2 —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π...")
        print(f"üìä –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(test_articles)} —Å—Ç–∞—Ç–µ–π")
        
        # –ü–µ—Ä–µ–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–µ—Ä–≤—É—é –∑–∞–¥–∞—á—É
        task_deduplicate.description += f"\n\n–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:\n{json.dumps(test_articles, ensure_ascii=False, indent=2)}"
        
        result = test_crew.kickoff()
        
        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ –¢–ï–°–¢–ê V2:")
        print(result)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}") 